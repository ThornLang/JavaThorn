name: Run Regression Tests (Bot)

on:
  # Run when both pr-tests and test workflows complete successfully
  workflow_run:
    workflows: ["PR-Specific Tests", "ThornLang CI"]
    types: [completed]
    branches: ["**"]
  
  # Keep the manual trigger via comment
  issue_comment:
    types: [created]

permissions:
  contents: read
  issues: write
  pull-requests: write
  actions: write

jobs:
  run-regression:
    runs-on: ubuntu-latest
    if: |
      (github.event_name == 'issue_comment' && 
       github.event.issue.pull_request && 
       contains(github.event.comment.body, '@run_regression')) ||
      (github.event_name == 'workflow_run' && 
       github.event.workflow_run.conclusion == 'success')
    
    steps:
    - name: Generate token
      id: generate-token
      uses: tibdex/github-app-token@v2
      with:
        app_id: ${{ secrets.THORN_LANG_APP_ID }}
        private_key: ${{ secrets.THORN_LANG_APP_PRIVATE_KEY }}
    
    - name: Add acknowledgment reaction (manual trigger only)
      if: github.event_name == 'issue_comment'
      uses: actions/github-script@v6
      with:
        github-token: ${{ steps.generate-token.outputs.token }}
        script: |
          github.rest.reactions.createForIssueComment({
            owner: context.repo.owner,
            repo: context.repo.repo,
            comment_id: context.payload.comment.id,
            content: 'rocket'
          });
    
    - name: Checkout code
      uses: actions/checkout@v3
      with:
        token: ${{ steps.generate-token.outputs.token }}
        ref: ${{ github.event_name == 'issue_comment' && format('refs/pull/{0}/head', github.event.issue.number) || github.event.workflow_run.head_sha }}
    
    - name: Set up Java
      uses: actions/setup-java@v3
      with:
        java-version: '17'
        distribution: 'temurin'
    
    - name: Build project
      run: |
        echo "ğŸ”¨ Building ThornLang..."
        chmod +x scripts/build.sh && ./scripts/build.sh
    
    - name: Run regression tests
      id: regression-tests
      run: |
        echo "ğŸ§ª Running regression tests..."
        REGRESSION_DIR="tests/regression"
        
        if [ ! -d "$REGRESSION_DIR" ]; then
          echo "âŒ No regression directory found at $REGRESSION_DIR"
          echo "status=no-tests" >> $GITHUB_OUTPUT
          exit 0
        fi
        
        # Count total test files
        TOTAL_TESTS=$(find "$REGRESSION_DIR" -name "*.thorn" -type f | wc -l)
        
        if [ "$TOTAL_TESTS" -eq 0 ]; then
          echo "âŒ No regression tests found in $REGRESSION_DIR"
          echo "status=no-tests" >> $GITHUB_OUTPUT
          exit 0
        fi
        
        echo "ğŸ“Š Found $TOTAL_TESTS regression tests"
        echo ""
        
        # Initialize counters and files
        echo "0" > /tmp/passed_count
        echo "0" > /tmp/failed_count
        echo "" > /tmp/failed_tests
        echo "" > /tmp/unexpected_results
        
        # Create logs directory
        mkdir -p /tmp/test_logs
        
        # Run each test file
        for test_file in $(find "$REGRESSION_DIR" -name "*.thorn" -type f | sort); do
          test_name=$(basename "$test_file")
          echo "Running: $test_name"
          
          # Run the test and capture output
          if java com.thorn.Thorn "$test_file" > "/tmp/test_logs/${test_name}.log" 2>&1; then
            # Test executed successfully (exit code 0)
            # Check output for test framework results
            if grep -q "All tests passed!" "/tmp/test_logs/${test_name}.log"; then
              echo "  âœ… PASSED (all tests passed)"
              PASSED=$(cat /tmp/passed_count)
              PASSED=$((PASSED + 1))
              echo "$PASSED" > /tmp/passed_count
            elif grep -q "Failed tests:" "/tmp/test_logs/${test_name}.log"; then
              echo "  âŒ FAILED (some tests failed)"
              echo "  Test output:"
              grep -A 10 "Failed tests:" "/tmp/test_logs/${test_name}.log" | sed 's/^/    /'
              FAILED=$(cat /tmp/failed_count)
              FAILED=$((FAILED + 1))
              echo "$FAILED" > /tmp/failed_count
              echo "- $test_name" >> /tmp/failed_tests
            else
              # No test framework output detected, check if it's a legacy test
              if [[ "$test_name" == *"_expectError"* ]]; then
                # Legacy test expecting error - mark as needing update
                echo "  âš ï¸  LEGACY TEST (needs update to new framework)"
                echo "- $test_name (legacy format)" >> /tmp/failed_tests
                FAILED=$(cat /tmp/failed_count)
                FAILED=$((FAILED + 1))
                echo "$FAILED" > /tmp/failed_count
              else
                # Assume success for non-framework tests
                echo "  âœ… PASSED (no test framework detected)"
                PASSED=$(cat /tmp/passed_count)
                PASSED=$((PASSED + 1))
                echo "$PASSED" > /tmp/passed_count
              fi
            fi
          else
            # Test failed with non-zero exit code
            echo "  âŒ FAILED (runtime error)"
            echo "  First 10 lines of output:"
            head -10 "/tmp/test_logs/${test_name}.log" | sed 's/^/    /'
            FAILED=$(cat /tmp/failed_count)
            FAILED=$((FAILED + 1))
            echo "$FAILED" > /tmp/failed_count
            echo "- $test_name" >> /tmp/failed_tests
          fi
          echo ""
        done
        
        # Read final counters from files
        PASSED=$(cat /tmp/passed_count)
        FAILED=$(cat /tmp/failed_count)
        FAILED_TESTS=$(cat /tmp/failed_tests | grep -v '^$' | tr '\n' ' ')
        
        # Summary
        echo "========================================"
        echo "ğŸ“Š Regression Test Summary"
        echo "========================================"
        echo "Total: $TOTAL_TESTS"
        echo "Passed: $PASSED âœ…"
        echo "Failed: $FAILED âŒ"
        
        if [ "$FAILED" -gt 0 ]; then
          echo ""
          if [ -s /tmp/failed_tests ]; then
            echo "Failed tests:"
            cat /tmp/failed_tests | grep -v '^$'
          fi
          if [ -s /tmp/unexpected_results ]; then
            echo "Unexpected results:"
            cat /tmp/unexpected_results | grep -v '^$'
          fi
          echo "status=failed" >> $GITHUB_OUTPUT
          echo "failed_count=$FAILED" >> $GITHUB_OUTPUT
          echo "passed_count=$PASSED" >> $GITHUB_OUTPUT
          echo "total_count=$TOTAL_TESTS" >> $GITHUB_OUTPUT
          exit 1
        else
          echo ""
          echo "ğŸ‰ All regression tests passed!"
          echo "status=passed" >> $GITHUB_OUTPUT
          echo "failed_count=0" >> $GITHUB_OUTPUT
          echo "passed_count=$PASSED" >> $GITHUB_OUTPUT
          echo "total_count=$TOTAL_TESTS" >> $GITHUB_OUTPUT
        fi
    
    - name: Upload test logs
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: regression-test-logs-${{ github.run_id }}
        path: /tmp/test_logs/
        retention-days: 7
    
    - name: Post results comment
      if: always()
      uses: actions/github-script@v6
      with:
        github-token: ${{ steps.generate-token.outputs.token }}
        script: |
          const status = '${{ steps.regression-tests.outputs.status }}';
          const passed = '${{ steps.regression-tests.outputs.passed_count }}' || '0';
          const failed = '${{ steps.regression-tests.outputs.failed_count }}' || '0';
          const total = '${{ steps.regression-tests.outputs.total_count }}' || '0';
          
          let message = '## ğŸ§ª Regression Test Results\n\n';
          
          if (status === 'no-tests') {
            message += 'âŒ No regression tests found in `tests/regression/`\n';
          } else if (status === 'passed') {
            message += `âœ… **All ${total} regression tests passed!**\n\n`;
            message += `- Passed: ${passed} âœ…\n`;
            message += `- Failed: ${failed} âŒ\n`;
          } else {
            message += `âŒ **${failed} of ${total} regression tests failed**\n\n`;
            message += `- Passed: ${passed} âœ…\n`;
            message += `- Failed: ${failed} âŒ\n\n`;
            message += 'Check the workflow logs for detailed failure information.';
          }
          
          // Get PR number based on trigger type
          let prNumber = null;
          
          if (context.eventName === 'issue_comment') {
            // Manual trigger
            prNumber = context.issue.number;
            message += '\n\n<sub>Triggered by @' + context.payload.comment.user.login + '</sub>';
            
            // Add reaction
            const reaction = status === 'passed' ? '+1' : (status === 'no-tests' ? 'confused' : '-1');
            github.rest.reactions.createForIssueComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              comment_id: context.payload.comment.id,
              content: reaction
            });
          } else if (context.eventName === 'workflow_run') {
            // Workflow completion trigger
            message += '\n\n<sub>Automatically triggered after PR tests and CI passed</sub>';
            
            // Get PR number from workflow run
            const pullRequests = context.payload.workflow_run.pull_requests;
            if (pullRequests && pullRequests.length > 0) {
              prNumber = pullRequests[0].number;
            }
          }
          
          // Always try to post comment if we have a PR number
          if (prNumber) {
            try {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: prNumber,
                body: message
              });
              console.log(`âœ… Posted regression test results to PR #${prNumber}`);
            } catch (error) {
              console.log(`âŒ Failed to post comment to PR #${prNumber}: ${error.message}`);
            }
          } else {
            console.log('âš ï¸ No PR number found, cannot post comment');
          }
          
          console.log(`ğŸ§ª Regression tests completed - Status: ${status}, Results: ${passed}/${total} passed`);