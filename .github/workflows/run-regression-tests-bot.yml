name: Run Regression Tests (Bot)

on:
  # Run when both pr-tests and test workflows complete successfully
  workflow_run:
    workflows: ["PR-Specific Tests", "ThornLang CI"]
    types: [completed]
    branches: ["**"]
  
  # Also run on pushes (when pr-tests and test would run)
  push:
    branches: ["main", "**"]
  
  # Keep the manual trigger via comment
  issue_comment:
    types: [created]

permissions:
  contents: read
  issues: write
  pull-requests: write
  actions: write

jobs:
  # Check if we should run regression tests
  check-prerequisites:
    runs-on: ubuntu-latest
    outputs:
      should-run: ${{ steps.check.outputs.should-run }}
      checkout-ref: ${{ steps.check.outputs.checkout-ref }}
      trigger-type: ${{ steps.check.outputs.trigger-type }}
    steps:
    - name: Check prerequisites
      id: check
      uses: actions/github-script@v6
      with:
        script: |
          const eventName = context.eventName;
          
          if (eventName === 'issue_comment') {
            // Manual trigger via comment
            const isManualTrigger = context.payload.issue.pull_request && 
                                   context.payload.comment.body.includes('@run_regression');
            if (isManualTrigger) {
              core.setOutput('should-run', 'true');
              core.setOutput('checkout-ref', `refs/pull/${context.payload.issue.number}/head`);
              core.setOutput('trigger-type', 'manual');
              return;
            }
          } else if (eventName === 'push') {
            // Push trigger - run directly
            core.setOutput('should-run', 'true');
            core.setOutput('checkout-ref', context.sha);
            core.setOutput('trigger-type', 'push');
            return;
          } else if (eventName === 'workflow_run') {
            // Workflow completion trigger
            const workflow = context.payload.workflow_run;
            const conclusion = workflow.conclusion;
            
            if (conclusion !== 'success') {
              console.log(`Workflow ${workflow.name} did not succeed (${conclusion}), skipping regression tests`);
              core.setOutput('should-run', 'false');
              return;
            }
            
            // Check if both required workflows have completed successfully for this commit
            const { owner, repo } = context.repo;
            const headSha = workflow.head_sha;
            
            // Get all workflow runs for this commit
            const { data: workflowRuns } = await github.rest.actions.listWorkflowRunsForRepo({
              owner,
              repo,
              head_sha: headSha,
              status: 'completed'
            });
            
            const requiredWorkflows = ['PR-Specific Tests', 'ThornLang CI'];
            const completedWorkflows = workflowRuns.workflow_runs
              .filter(run => requiredWorkflows.includes(run.name) && run.conclusion === 'success')
              .map(run => run.name);
            
            console.log(`Required workflows: ${requiredWorkflows.join(', ')}`);
            console.log(`Completed successful workflows: ${completedWorkflows.join(', ')}`);
            
            if (completedWorkflows.length >= requiredWorkflows.length) {
              core.setOutput('should-run', 'true');
              core.setOutput('checkout-ref', headSha);
              core.setOutput('trigger-type', 'workflow-completion');
            } else {
              console.log('Not all required workflows have completed successfully yet');
              core.setOutput('should-run', 'false');
            }
            return;
          }
          
          core.setOutput('should-run', 'false');

  run-regression:
    runs-on: ubuntu-latest
    needs: check-prerequisites
    if: needs.check-prerequisites.outputs.should-run == 'true'
    
    steps:
    - name: Generate token
      id: generate-token
      uses: tibdex/github-app-token@v2
      with:
        app_id: ${{ secrets.THORN_LANG_APP_ID }}
        private_key: ${{ secrets.THORN_LANG_APP_PRIVATE_KEY }}
    
    - name: Add acknowledgment reaction (manual trigger only)
      if: needs.check-prerequisites.outputs.trigger-type == 'manual'
      uses: actions/github-script@v6
      with:
        github-token: ${{ steps.generate-token.outputs.token }}
        script: |
          github.rest.reactions.createForIssueComment({
            owner: context.repo.owner,
            repo: context.repo.repo,
            comment_id: context.payload.comment.id,
            content: 'rocket'
          });
    
    - name: Checkout code
      uses: actions/checkout@v3
      with:
        token: ${{ steps.generate-token.outputs.token }}
        ref: ${{ needs.check-prerequisites.outputs.checkout-ref }}
    
    - name: Set up Java
      uses: actions/setup-java@v3
      with:
        java-version: '17'
        distribution: 'temurin'
    
    - name: Build project
      run: |
        echo "🔨 Building ThornLang..."
        chmod +x scripts/build.sh && ./scripts/build.sh
    
    - name: Run regression tests
      id: regression-tests
      run: |
        echo "🧪 Running regression tests..."
        REGRESSION_DIR="tests/regression"
        
        if [ ! -d "$REGRESSION_DIR" ]; then
          echo "❌ No regression directory found at $REGRESSION_DIR"
          echo "status=no-tests" >> $GITHUB_OUTPUT
          exit 0
        fi
        
        # Count total test files
        TOTAL_TESTS=$(find "$REGRESSION_DIR" -name "*.thorn" -type f | wc -l)
        
        if [ "$TOTAL_TESTS" -eq 0 ]; then
          echo "❌ No regression tests found in $REGRESSION_DIR"
          echo "status=no-tests" >> $GITHUB_OUTPUT
          exit 0
        fi
        
        echo "📊 Found $TOTAL_TESTS regression tests"
        echo ""
        
        # Initialize counters and files
        echo "0" > /tmp/passed_count
        echo "0" > /tmp/failed_count
        echo "" > /tmp/failed_tests
        echo "" > /tmp/unexpected_results
        
        # Create logs directory
        mkdir -p /tmp/test_logs
        
        # Run each test file
        for test_file in $(find "$REGRESSION_DIR" -name "*.thorn" -type f | sort); do
          test_name=$(basename "$test_file")
          echo "Running: $test_name"
          
          # Determine expected behavior based on filename
          if [[ "$test_name" == *"_expectError"* ]]; then
            EXPECT_FAILURE=true
            echo "  (expecting error)"
          elif [[ "$test_name" == *"_expectNoError"* ]]; then
            EXPECT_FAILURE=false
            echo "  (expecting success)"
          else
            # Default behavior - expect success
            EXPECT_FAILURE=false
          fi
          
          # Run the test and capture output
          if java com.thorn.Thorn "$test_file" > "/tmp/test_logs/${test_name}.log" 2>&1; then
            # Test executed successfully
            if [ "$EXPECT_FAILURE" = true ]; then
              echo "  ❌ UNEXPECTED PASS (expected to fail)"
              echo "    Test succeeded but was expected to fail"
              FAILED=$(cat /tmp/failed_count)
              FAILED=$((FAILED + 1))
              echo "$FAILED" > /tmp/failed_count
              echo "- $test_name (unexpected pass)" >> /tmp/unexpected_results
            else
              echo "  ✅ PASSED"
              PASSED=$(cat /tmp/passed_count)
              PASSED=$((PASSED + 1))
              echo "$PASSED" > /tmp/passed_count
            fi
          else
            # Test failed
            if [ "$EXPECT_FAILURE" = true ]; then
              echo "  ✅ EXPECTED FAILURE"
              PASSED=$(cat /tmp/passed_count)
              PASSED=$((PASSED + 1))
              echo "$PASSED" > /tmp/passed_count
            else
              echo "  ❌ FAILED"
              echo "  First 10 lines of output:"
              head -10 "/tmp/test_logs/${test_name}.log" | sed 's/^/    /'
              FAILED=$(cat /tmp/failed_count)
              FAILED=$((FAILED + 1))
              echo "$FAILED" > /tmp/failed_count
              echo "- $test_name" >> /tmp/failed_tests
            fi
          fi
          echo ""
        done
        
        # Read final counters from files
        PASSED=$(cat /tmp/passed_count)
        FAILED=$(cat /tmp/failed_count)
        FAILED_TESTS=$(cat /tmp/failed_tests | grep -v '^$' | tr '\n' ' ')
        
        # Summary
        echo "========================================"
        echo "📊 Regression Test Summary"
        echo "========================================"
        echo "Total: $TOTAL_TESTS"
        echo "Passed: $PASSED ✅"
        echo "Failed: $FAILED ❌"
        
        if [ "$FAILED" -gt 0 ]; then
          echo ""
          if [ -s /tmp/failed_tests ]; then
            echo "Failed tests:"
            cat /tmp/failed_tests | grep -v '^$'
          fi
          if [ -s /tmp/unexpected_results ]; then
            echo "Unexpected results:"
            cat /tmp/unexpected_results | grep -v '^$'
          fi
          echo "status=failed" >> $GITHUB_OUTPUT
          echo "failed_count=$FAILED" >> $GITHUB_OUTPUT
          echo "passed_count=$PASSED" >> $GITHUB_OUTPUT
          echo "total_count=$TOTAL_TESTS" >> $GITHUB_OUTPUT
          exit 1
        else
          echo ""
          echo "🎉 All regression tests passed!"
          echo "status=passed" >> $GITHUB_OUTPUT
          echo "failed_count=0" >> $GITHUB_OUTPUT
          echo "passed_count=$PASSED" >> $GITHUB_OUTPUT
          echo "total_count=$TOTAL_TESTS" >> $GITHUB_OUTPUT
        fi
    
    - name: Upload test logs
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: regression-test-logs-${{ github.sha }}-${{ needs.check-prerequisites.outputs.trigger-type }}
        path: /tmp/test_logs/
        retention-days: 7
    
    - name: Post results comment
      if: always()
      uses: actions/github-script@v6
      with:
        github-token: ${{ steps.generate-token.outputs.token }}
        script: |
          const status = '${{ steps.regression-tests.outputs.status }}';
          const passed = '${{ steps.regression-tests.outputs.passed_count }}' || '0';
          const failed = '${{ steps.regression-tests.outputs.failed_count }}' || '0';
          const total = '${{ steps.regression-tests.outputs.total_count }}' || '0';
          const triggerType = '${{ needs.check-prerequisites.outputs.trigger-type }}';
          
          let message = '## 🧪 Regression Test Results\n\n';
          
          if (status === 'no-tests') {
            message += '❌ No regression tests found in `tests/regression/`\n';
          } else if (status === 'passed') {
            message += `✅ **All ${total} regression tests passed!**\n\n`;
            message += `- Passed: ${passed} ✅\n`;
            message += `- Failed: ${failed} ❌\n`;
          } else {
            message += `❌ **${failed} of ${total} regression tests failed**\n\n`;
            message += `- Passed: ${passed} ✅\n`;
            message += `- Failed: ${failed} ❌\n\n`;
            message += 'Check the workflow logs for detailed failure information.';
          }
          
          // Add trigger info based on type
          if (triggerType === 'manual') {
            message += '\n\n<sub>Triggered by @' + context.payload.comment.user.login + '</sub>';
          } else if (triggerType === 'workflow-completion') {
            message += '\n\n<sub>Automatically triggered after PR tests and CI passed</sub>';
          } else if (triggerType === 'push') {
            message += '\n\n<sub>Automatically triggered by push to branch</sub>';
          }
          
          // For PRs (manual trigger or workflow completion), post comment
          if (triggerType === 'manual' || (triggerType === 'workflow-completion' && context.payload.workflow_run.event === 'pull_request')) {
            const issueNumber = triggerType === 'manual' ? 
              context.issue.number : 
              context.payload.workflow_run.pull_requests[0]?.number;
              
            if (issueNumber) {
              github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                body: message
              });
            }
          }
          
          // Add reaction for manual triggers
          if (triggerType === 'manual') {
            const reaction = status === 'passed' ? '+1' : (status === 'no-tests' ? 'confused' : '-1');
            github.rest.reactions.createForIssueComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              comment_id: context.payload.comment.id,
              content: reaction
            });
          }
          
          // Always log results
          console.log(`🧪 Regression tests completed`);
          console.log(`Trigger type: ${triggerType}`);
          console.log(`Status: ${status}`);
          console.log(`Results: ${passed}/${total} passed`);